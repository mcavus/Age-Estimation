{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mcavus/Age-Estimation/blob/master/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "krzbanZM4Oht",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1544
        },
        "outputId": "2d33be77-23d8-4f76-d4ab-4f75fa1c7544"
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "CS 559: Deep Learning\n",
        "Homework: Age Estimation using TensorFlow\n",
        "Muhammed Cavusoglu (21400653) and Kemal Buyukkaya (21200496)\n",
        "'''\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# For colab\n",
        "'''\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "'''\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.INFO)\n",
        "\n",
        "def cnn_model(features, labels, mode):\n",
        "    # Input Layer\n",
        "    # Reshape input to 4-D tensor: [batch_size, width, height, channels]\n",
        "    input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n",
        "    \n",
        "    # Conv1 Layer\n",
        "    # Compute 32 features using a 5x5 filter with ReLU activation.\n",
        "    # Padding is added to preserve width and height.\n",
        "    # Input Tensor Shape: [batch_size, 28, 28, 1]\n",
        "    # Output Tensor Shape: [batch_size, 28, 28, 32]\n",
        "    conv1 = tf.contrib.layers.conv2d(\n",
        "        inputs = input_layer,\n",
        "        num_outputs = 32,\n",
        "        kernel_size = [3, 3],\n",
        "        padding= 'SAME',\n",
        "        activation_fn = tf.nn.relu,\n",
        "        weights_initializer=tf.contrib.layers.xavier_initializer()\n",
        "    )\n",
        "    \n",
        "    # Pooling1 Layer\n",
        "    # Max pooling layer with a 2x2 filter and stride of 2\n",
        "    # Input Tensor Shape: [batch_size, 28, 28, 32]\n",
        "    # Output Tensor Shape: [batch_size, 14, 14, 32]\n",
        "    pool1 = tf.contrib.layers.max_pool2d(inputs = conv1, kernel_size = [2, 2], stride = 2)\n",
        "    \n",
        "    bn1 = tf.contrib.layers.batch_norm(inputs = pool1, activation_fn = None)\n",
        "\n",
        "    # Conv2 Layer\n",
        "    # Compute 64 features using a 5x5 filter.\n",
        "    # Padding is added to preserve width and height.\n",
        "    # Input Tensor Shape: [batch_size, 14, 14, 32]\n",
        "    # Output Tensor Shape: [batch_size, 14, 14, 64]\n",
        "    conv2 = tf.contrib.layers.conv2d(\n",
        "        inputs = bn1,\n",
        "        num_outputs = 64,\n",
        "        kernel_size = [3, 3],\n",
        "        padding= 'SAME',\n",
        "        activation_fn = tf.nn.relu,\n",
        "        weights_initializer=tf.contrib.layers.xavier_initializer()\n",
        "    )\n",
        "    \n",
        "\n",
        "    # Pooling 2 Layer\n",
        "    # Max pooling layer with a 2x2 filter and stride of 2\n",
        "    # Input Tensor Shape: [batch_size, 14, 14, 64]\n",
        "    # Output Tensor Shape: [batch_size, 7, 7, 64]\n",
        "    pool2 = tf.contrib.layers.max_pool2d(inputs = conv2, kernel_size = [2, 2], stride = 2)\n",
        "    \n",
        "    bn2 = tf.contrib.layers.batch_norm(inputs = pool2, activation_fn = None)\n",
        "    \n",
        "    # Flatten tensor into a batch of vectors\n",
        "    # Input Tensor Shape: [batch_size, 7, 7, 64]\n",
        "    # Output Tensor Shape: [batch_size, 7 * 7 * 64]\n",
        "    pool2_flat = tf.reshape(bn2, [-1, 7 * 7 * 64])\n",
        "\n",
        "    # FC Layer with 1024 neurons\n",
        "    # Input Tensor Shape: [batch_size, 7 * 7 * 64]\n",
        "    # Output Tensor Shape: [batch_size, 1024]\n",
        "    fc1 = tf.contrib.layers.fully_connected(inputs = pool2_flat, num_outputs = 1024, activation_fn = None, \n",
        "                                           weights_initializer=tf.contrib.layers.xavier_initializer())\n",
        "    \n",
        "    bn3 = tf.contrib.layers.batch_norm(inputs = fc1, activation_fn = tf.nn.relu)\n",
        "\n",
        "    fc2 = tf.contrib.layers.fully_connected(inputs = bn3, num_outputs = 1024, activation_fn = None, \n",
        "                                           weights_initializer=tf.contrib.layers.xavier_initializer())\n",
        "    \n",
        "    bn4 = tf.contrib.layers.batch_norm(inputs = fc2, activation_fn = tf.nn.relu)\n",
        "\n",
        "    # Dropout (0.6 probability for keeping the element)\n",
        "    dropout = tf.contrib.layers.dropout(inputs = bn4, keep_prob = 1, is_training = (mode == tf.estimator.ModeKeys.TRAIN))\n",
        "    \n",
        "    # Regression Layer\n",
        "    # Input Tensor Shape: [batch_size, 1024]\n",
        "    # Output Tensor Shape: [batch_size, 1]\n",
        "    regression = tf.contrib.layers.fully_connected(inputs = dropout, num_outputs = 1, activation_fn = None)\n",
        "    \n",
        "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
        "      return tf.estimator.EstimatorSpec(mode = mode, predictions = regression)\n",
        "    \n",
        "    # Loss function\n",
        "    loss = tf.losses.mean_squared_error(labels = labels, predictions = regression)\n",
        "    \n",
        "    # Configure the Training Op (for TRAIN mode)\n",
        "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "      optimizer = tf.train.AdamOptimizer(learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-08, use_locking=False, name='Adam')\n",
        "      train_op = optimizer.minimize(\n",
        "          loss = loss,\n",
        "          global_step = tf.train.get_global_step())\n",
        "      return tf.estimator.EstimatorSpec(mode = mode, loss = loss, train_op = train_op)\n",
        "\n",
        "    # Add evaluation metrics (for EVAL mode)\n",
        "    eval_metric_ops = {\n",
        "        \"MAE\": tf.metrics.mean_absolute_error(labels = labels, predictions = regression)\n",
        "    }\n",
        "    \n",
        "    return tf.estimator.EstimatorSpec(mode = mode, loss = loss, eval_metric_ops = eval_metric_ops)\n",
        "\n",
        "\n",
        "def main(argv):\n",
        "    # Load the data\n",
        "    # Use below to re-generate npy files\n",
        "    # training_data, training_labels, validation_data, validation_labels, test_data, test_labels = _load_dataset()\n",
        "    \n",
        "    # For colab\n",
        "    training_data = np.load(\"/content/drive/My Drive/Colab Notebooks/training_data.npy\")\n",
        "    training_labels = np.load(\"/content/drive/My Drive/Colab Notebooks/training_labels.npy\")\n",
        "    validation_data = np.load(\"/content/drive/My Drive/Colab Notebooks/validation_data.npy\")\n",
        "    validation_labels = np.load(\"/content/drive/My Drive/Colab Notebooks/validation_labels.npy\")\n",
        "    test_data = np.load(\"/content/drive/My Drive/Colab Notebooks/test_data.npy\")\n",
        "    test_labels = np.load(\"/content/drive/My Drive/Colab Notebooks/test_labels.npy\")\n",
        "    \n",
        "    # For local \n",
        "    '''\n",
        "    training_data = np.load(\"training_data.npy\")\n",
        "    training_labels = np.load(\"training_labels.npy\")\n",
        "    validation_data = np.load(\"validation_data.npy\")\n",
        "    validation_labels = np.load(\"validation_labels.npy\")\n",
        "    test_data = np.load(\"test_data.npy\")\n",
        "    test_labels = np.load(\"test_labels.npy\")\n",
        "    '''\n",
        "    \n",
        "    # Estimator\n",
        "    age_estimator = tf.estimator.Estimator(model_fn = cnn_model)\n",
        "    \n",
        "    # Train the model\n",
        "    train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
        "        x = {\"x\": training_data},\n",
        "        y = training_labels,\n",
        "        batch_size = 256,\n",
        "        num_epochs = None,\n",
        "        shuffle=True)\n",
        "        \n",
        "    age_estimator.train(\n",
        "        input_fn = train_input_fn,\n",
        "        steps=1200)\n",
        "\n",
        "    # Evaluate the model and print results\n",
        "    eval_input_fn = tf.estimator.inputs.numpy_input_fn(x={\"x\": test_data}, y = test_labels, num_epochs = 1, shuffle = False)\n",
        "    #eval_input_fn = tf.estimator.inputs.numpy_input_fn(x={\"x\": validation_data}, y = validation_labels, num_epochs = 1, shuffle = False)\n",
        "    #eval_input_fn = tf.estimator.inputs.numpy_input_fn(x={\"x\": training_data}, y = training_labels, num_epochs = 1, shuffle = False)\n",
        "\n",
        "    eval_results = age_estimator.evaluate(input_fn = eval_input_fn)\n",
        "    print(eval_results)\n",
        "    \n",
        "def _load_dataset():\n",
        "    # Training set\n",
        "    training_data = []\n",
        "    training_labels = []\n",
        "    \n",
        "    tr_path = 'UTKFace_downsampled/training_set'\n",
        "    for filename in os.listdir(tr_path):\n",
        "        training_labels.append(int(filename[:3]))\n",
        "        img_data = cv2.imread(os.path.join(tr_path, filename), cv2.IMREAD_GRAYSCALE).astype(np.float32)\n",
        "        img_data = cv2.resize(img_data, (28, 28)) # Resize\n",
        "        training_data.append(img_data)\n",
        "        \n",
        "    training_data = np.array(training_data, dtype='float32')\n",
        "    training_labels = np.array(training_labels, dtype='float32')\n",
        "    training_labels = training_labels.reshape(len(training_labels), 1)\n",
        "    np.save('training_data', training_data)\n",
        "    np.save('training_labels', training_labels)\n",
        "    \n",
        "    # Validation set\n",
        "    validation_data = []\n",
        "    validation_labels = []\n",
        "    \n",
        "    v_path = 'UTKFace_downsampled/validation_set'\n",
        "    for filename in os.listdir(v_path):\n",
        "        validation_labels.append(int(filename[:3]))\n",
        "        img_data = cv2.imread(os.path.join(v_path, filename), cv2.IMREAD_GRAYSCALE).astype(np.float32)\n",
        "        img_data = cv2.resize(img_data, (28, 28)) # Resize\n",
        "        validation_data.append(img_data)\n",
        "        \n",
        "    validation_data = np.array(validation_data, dtype='float32')\n",
        "    validation_labels = np.array(validation_labels, dtype='float32')\n",
        "    validation_labels = validation_labels.reshape(len(validation_labels), 1)\n",
        "    np.save('validation_data', validation_data)\n",
        "    np.save('validation_labels', validation_labels)\n",
        "    \n",
        "    # Test set\n",
        "    test_data = []\n",
        "    test_labels = []\n",
        "    \n",
        "    t_path = 'UTKFace_downsampled/test_set'\n",
        "    for filename in os.listdir(t_path):\n",
        "        test_labels.append(int(filename[:3]))\n",
        "        img_data = cv2.imread(os.path.join(t_path, filename), cv2.IMREAD_GRAYSCALE).astype(np.float32)\n",
        "        img_data = cv2.resize(img_data, (28, 28)) # Resize\n",
        "        test_data.append(img_data)\n",
        "        \n",
        "    test_data = np.array(test_data, dtype='float32')\n",
        "    test_labels = np.array(test_labels, dtype='float32')\n",
        "    test_labels = test_labels.reshape(len(test_labels), 1)\n",
        "    np.save('test_data', test_data)\n",
        "    np.save('test_labels', test_labels)\n",
        "    \n",
        "    return training_data, training_labels, validation_data, validation_labels, test_data, test_labels\n",
        "    \n",
        "if __name__ == \"__main__\":\n",
        "  tf.app.run()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpt6aa1ly9\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpt6aa1ly9', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fb6b8a1a630>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/losses/losses_impl.py:667: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py:809: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpt6aa1ly9/model.ckpt.\n",
            "INFO:tensorflow:loss = 1385.4003, step = 0\n",
            "INFO:tensorflow:global_step/sec: 50.8699\n",
            "INFO:tensorflow:loss = 39.35098, step = 100 (1.971 sec)\n",
            "INFO:tensorflow:global_step/sec: 56.2694\n",
            "INFO:tensorflow:loss = 11.76229, step = 200 (1.774 sec)\n",
            "INFO:tensorflow:global_step/sec: 56.4981\n",
            "INFO:tensorflow:loss = 17.476246, step = 300 (1.772 sec)\n",
            "INFO:tensorflow:global_step/sec: 56.3705\n",
            "INFO:tensorflow:loss = 8.588813, step = 400 (1.772 sec)\n",
            "INFO:tensorflow:global_step/sec: 56.0722\n",
            "INFO:tensorflow:loss = 4.7220707, step = 500 (1.786 sec)\n",
            "INFO:tensorflow:global_step/sec: 56.2705\n",
            "INFO:tensorflow:loss = 3.282241, step = 600 (1.774 sec)\n",
            "INFO:tensorflow:global_step/sec: 56.4582\n",
            "INFO:tensorflow:loss = 3.468257, step = 700 (1.771 sec)\n",
            "INFO:tensorflow:global_step/sec: 56.2174\n",
            "INFO:tensorflow:loss = 14.337393, step = 800 (1.779 sec)\n",
            "INFO:tensorflow:global_step/sec: 56.4742\n",
            "INFO:tensorflow:loss = 5.7765045, step = 900 (1.770 sec)\n",
            "INFO:tensorflow:global_step/sec: 56.1993\n",
            "INFO:tensorflow:loss = 3.2047224, step = 1000 (1.783 sec)\n",
            "INFO:tensorflow:global_step/sec: 55.7748\n",
            "INFO:tensorflow:loss = 3.072467, step = 1100 (1.794 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 1200 into /tmp/tmpt6aa1ly9/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 2.9436367.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2019-04-01T10:02:52Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpt6aa1ly9/model.ckpt-1200\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2019-04-01-10:02:52\n",
            "INFO:tensorflow:Saving dict for global step 1200: MAE = 7.568881, global_step = 1200, loss = 103.779724\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1200: /tmp/tmpt6aa1ly9/model.ckpt-1200\n",
            "{'MAE': 7.568881, 'loss': 103.779724, 'global_step': 1200}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}